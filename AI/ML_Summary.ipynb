{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7297b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c352ae4",
   "metadata": {},
   "source": [
    "### Data Import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee525910",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data. titanic data, from Kaggle.\n",
    "data_input = pd.read_csv('./data/titanic_train.csv')\n",
    "data_test  = pd.read_csv('./data/titanic_test.csv')\n",
    "\n",
    "data_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c54a25a",
   "metadata": {},
   "source": [
    "### Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7e43a4aa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Name         891 non-null    object \n",
      " 3   Sex          891 non-null    object \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Cabin        204 non-null    object \n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  889 non-null    int64  \n",
      " 1   Pclass       889 non-null    int64  \n",
      " 2   Name         889 non-null    object \n",
      " 3   Sex          889 non-null    object \n",
      " 4   Age          889 non-null    float64\n",
      " 5   SibSp        889 non-null    int64  \n",
      " 6   Parch        889 non-null    int64  \n",
      " 7   Ticket       889 non-null    object \n",
      " 8   Fare         889 non-null    float64\n",
      " 9   Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 76.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import OneHotEncoder\\none_enc = OneHotEncoder()\\ndata_train_prep_cat = one_enc.fit_transform(data_train_cpy_cat)    \\none_enc.categories_\\ndata_train_prep_cat.toarray()   #scipy sparse matrix -> np.ndarray\\n'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate target var 'Survived' before preprocessing.\n",
    "data_copy = data_input.copy()\n",
    "data_y = data_copy['Survived']\n",
    "data   = data_copy.drop(columns=['Survived'])\n",
    "\n",
    "#1. Numerical data.\n",
    "#1) Null check.\n",
    "data.info()  #Null values in 'Age', 'Cabin', 'Embarked'.\n",
    "#1 - Delete row without 'Embarked'.\n",
    "data = data.dropna(subset=['Embarked'])\n",
    "#2 - Delete col 'Cabin'.\n",
    "data = data.drop(columns=['Cabin'])\n",
    "#3 - Fill nulls in 'Age' with mean value.\n",
    "mean_age              = data['Age'].mean()\n",
    "data['Age']           = data['Age'].fillna(mean_age)\n",
    "data.info()\n",
    "\n",
    "#Null check (sklearn.impute).\n",
    "cols_cat           = data.select_dtypes('object').columns  #col names of cat cols.\n",
    "data_cat           = data[cols_cat]                        #get cat cols.\n",
    "data_num           = data.drop(columns=cols_cat)           #get num cols.\n",
    "cols_num           = data_num.columns                      #col names of num cols.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')    #fill null values with median value for each col.\n",
    "imputer.fit(data_num)                         #automatically calculates each median.\n",
    "data_num_prep = imputer.transform(data_num)   #actually fill in given data.\n",
    "imputer.statistics_                           #save median values for each num col.\n",
    "\n",
    "#data_train_prep = imputer.fit_transform(data_train_cpy_num)   #at once!\n",
    "\n",
    "data_num_prep = pd.DataFrame(data_num,        #returned dtype is np.ndarray -> pd.DataFrame.\n",
    "                             columns=cols_num, index=data_num.index)\n",
    "\n",
    "\n",
    "#2) Feature scaling.\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "mmx_sclr = MinMaxScaler()\n",
    "mmx_sclr.fit_transform(data_num_prep)\n",
    "\n",
    "#2. Categorical data.\n",
    "#1) Null check.\n",
    "#2) Cat -> Num.\n",
    "    #Ordinal encoder.\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ord_enc = OrdinalEncoder()\n",
    "data_cat_prep = ord_enc.fit_transform(data_cat)\n",
    "ord_enc.categories_    #saves which ordinal number is assigned for each col's value.\n",
    "\n",
    "    #One-hot encoder.\n",
    "'''\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_enc = OneHotEncoder()\n",
    "data_train_prep_cat = one_enc.fit_transform(data_train_cpy_cat)    \n",
    "one_enc.categories_\n",
    "data_train_prep_cat.toarray()   #scipy sparse matrix -> np.ndarray\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "89b5d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline.\n",
    "#Each preprocessing unit should be independent & asynchronized.\n",
    "\n",
    "#separate target var 'Survived' before preprocessing.\n",
    "data_copy = data_input.copy()\n",
    "data_y = data_copy['Survived']\n",
    "data   = data_copy.drop(columns=['Survived'])\n",
    "\n",
    "#Numerical data.\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe_num = Pipeline([\n",
    "    ('imp_num', SimpleImputer(strategy='mean')),\n",
    "    ('sclr_mmx', MinMaxScaler()),\n",
    "])\n",
    "\n",
    "#Categorical data.\n",
    "pipe_cat = Pipeline([\n",
    "    ('imp_cat', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc_ord', OrdinalEncoder()),\n",
    "    ('sclr_mmx', MinMaxScaler())\n",
    "])\n",
    "\n",
    "#Numerical + Categorical.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "pipe_prep = ColumnTransformer([                 #<Note> order or cols change, cols_num + cols_cat!\n",
    "    ('pipe_num', pipe_num, cols_num),\n",
    "    ('pipe_cat', pipe_cat, cols_cat)\n",
    "])\n",
    "data_prep = pipe_prep.fit_transform(data)\n",
    "cols_prep = cols_num.tolist() + cols_cat.tolist()\n",
    "data_prep = pd.DataFrame(data_prep, columns=cols_prep, index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859fc9b",
   "metadata": {},
   "source": [
    "### Model Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "66413e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt': 0.7761, 'svc': 0.7985}\n"
     ]
    }
   ],
   "source": [
    "#train-val split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(data_prep, data_y, train_size=0.7, stratify=data_y)\n",
    "\n",
    "#Try several candidates.\n",
    "accuracy = {}\n",
    "\n",
    "    #dt.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(train_x, train_y)\n",
    "val_y_pred = clf_dt.predict(val_x)\n",
    "accuracy['dt'] = round(sum(val_y.to_numpy() == val_y_pred) / len(val_y), 4)\n",
    "\n",
    "    #svm.\n",
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC()\n",
    "clf_svc.fit(train_x, train_y)\n",
    "val_y_pred = clf_svc.predict(val_x)\n",
    "accuracy['svc'] = round(sum(val_y.to_numpy() == val_y_pred) / len(val_y), 4)\n",
    "\n",
    "#k-cross validation.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy_10 = cross_val_score(clf_dt, data_prep, data_y, cv=10, scoring='accuracy')\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b146f89",
   "metadata": {},
   "source": [
    "### Model tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a759ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparams, grid search.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "hyperparams_grid = [\n",
    "    {'C' : [1.0, 2.0, 3.0], 'degree' : [3, 5, 10]},\n",
    "    {'C' : [1.0, 3.0], 'shrinking' : [True, False]}\n",
    "]\n",
    "clf_svc = SVC()\n",
    "grid_search = GridSearchCV(clf_svc, hyperparams_grid, cv=5,\n",
    "                           scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(data_prep, data_y)\n",
    "grid_search.best_params_\n",
    "grid_search.best_estimator_\n",
    "grid_search.best_score_\n",
    "grid_search.cv_results_          #train & test scores for each combination. fit time.\n",
    "\n",
    "#Randomized search.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf_svc = SVC()\n",
    "rand_search = RandomizedSearchCV(clf_svc, hyperparams_grid, cv=5,\n",
    "                                 scoring='accuracy', return_train_score=True)\n",
    "rand_search.fit(data_prep, data_y)\n",
    "\n",
    "clf_svc = grid_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
